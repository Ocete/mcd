{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opposite-cartoon",
   "metadata": {
    "id": "opposite-cartoon"
   },
   "source": [
    "\n",
    "# PIT - Práctica 2: Modelos ocultos de Markov (HMM)\n",
    "\n",
    "**Alicia Lozano Díez** y **Pablo Ramírez Hereza**\n",
    " \n",
    "21 de febrero de 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-camping",
   "metadata": {
    "id": "interracial-camping"
   },
   "source": [
    "## Objetivos\n",
    "\n",
    "Los objetivos de esta práctica son:\n",
    "* Comprobación de las características de un HMM en función de sus parámetros.\n",
    "* Resolución de los tres problemas asociados a un modelo oculto de Markov:\n",
    "    * Cálculo de la verosimilitud de una secuencia de observaciones y un HMM mediante la implementación del algoritmo *Forward*.\n",
    "    * Obtención de la secuencia de estados más probable dada una secuencia de observaciones mediante la implementación del algoritmo de *Viterbi*.\n",
    "    * Entrenamiento de un HMM con *EM*, en concreto el algoritmo *Baum-Welch*.\n",
    "* Utilización del paquete `hmmlearn` de `python` para la implementación de los algoritmos anteriores.\n",
    "* Utilización de HMMs en un caso práctico de clasificación de patrones temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-company",
   "metadata": {
    "id": "arbitrary-company"
   },
   "source": [
    "## Materiales - Moodle\n",
    "Los materiales proporcionados para esta práctica son:\n",
    "- Guión (.ipynb) de la práctica\n",
    "- Bases de datos para el ejercicio 3.\n",
    "  - sin_averias.csv\n",
    "  - fallo_componente.csv\n",
    "  - uso_inapropiado.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "AJu5z1bn1_G-",
   "metadata": {
    "id": "AJu5z1bn1_G-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.2.7.tar.gz (53 kB)\n",
      "     ---------------------------------------- 53.5/53.5 KB 2.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for hmmlearn did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [48 lines of output]\n",
      "  c:\\users\\ocete\\appdata\\local\\temp\\pip-install-k3761pq8\\hmmlearn_b26ab6b60c4f4ae9a66517e7f70e7a03\\.eggs\\setuptools_scm-6.4.2-py3.7.egg\\setuptools_scm\\integration.py:39: RuntimeWarning:\n",
      "  ERROR: setuptools==39.0.1 is used in combination with setuptools_scm>=6.x\n",
      "  \n",
      "  Your build configuration is incomplete and previously worked by accident!\n",
      "  \n",
      "  \n",
      "  This happens as setuptools is unable to replace itself when a activated build dependency\n",
      "  requires a more recent setuptools version\n",
      "  (it does not respect \"setuptools>X\" in setup_requires).\n",
      "  \n",
      "  \n",
      "  setuptools>=31 is required for setup.cfg metadata support\n",
      "  setuptools>=42 is required for pyproject.toml configuration support\n",
      "  \n",
      "  Suggested workarounds if applicable:\n",
      "   - preinstalling build dependencies like setuptools_scm before running setup.py\n",
      "   - installing setuptools_scm using the system package manager to ensure consistency\n",
      "   - migrating from the deprecated setup_requires mechanism to pep517/518\n",
      "     and using a pyproject.toml to declare build dependencies\n",
      "     which are reliably pre-installed before running the build tools\n",
      "  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\ocete\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from hmmlearn) (1.21.3)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in c:\\users\\ocete\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from hmmlearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\ocete\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from hmmlearn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ocete\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ocete\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from scikit-learn>=0.16->hmmlearn) (3.0.0)\n",
      "Using legacy 'setup.py install' for hmmlearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: hmmlearn\n",
      "  Running setup.py install for hmmlearn: started\n",
      "  Running setup.py install for hmmlearn: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    \"\"\"\n",
      "  running install\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win32-3.7\n",
      "  creating build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\base.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\hmm.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\stats.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\utils.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\_utils.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\_version.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  copying lib\\hmmlearn\\__init__.py -> build\\lib.win32-3.7\\hmmlearn\n",
      "  creating build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\conftest.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_base.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_gaussian_hmm.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_gmm_hmm.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_gmm_hmm_multisequence.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_gmm_hmm_new.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_multinomial_hmm.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\test_utils.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  copying lib\\hmmlearn\\tests\\__init__.py -> build\\lib.win32-3.7\\hmmlearn\\tests\n",
      "  running build_ext\n",
      "  building 'hmmlearn._hmmc' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "hmmlearn\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cloudy-sacrifice",
   "metadata": {
    "id": "cloudy-sacrifice"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hmmlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3764/423668487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhmmlearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hmmlearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-affiliate",
   "metadata": {
    "id": "basic-affiliate"
   },
   "source": [
    "## PARTE 1: Introducción a los Modelos Ocultos de Markov (HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-office",
   "metadata": {
    "id": "traditional-office"
   },
   "source": [
    "### 1.1 Definición de un modelo oculto de Markov\n",
    "\n",
    "Los modelos ocultos de Markov (*Hidden Markov Model* o *HMM*) es un modelo probabilístico generativo, en el cual una secuencia de variables observables $\\mathrm{X}$ es generada por una secuencia de estados ocultos internos $\\mathbf{\\mathrm{Z}}$. Las transiciones entre estados se asume que siguen la forma de una cadena de Markov de primer orden, de tal forma que el estado en un instante determinado *t* solo depende del estado del modelo en el instante anterior *t-1*.\n",
    "\n",
    "Un HMM se encuentra definido por:\n",
    "* El número de estados del modelo $N$.\n",
    "* Probabilidades iniciales de ocupación de cada estado $\\pi$.\n",
    "* Matriz de probabilidades de transición entre estados $\\mathbf{A}$.\n",
    "* Distribución de probabilidad de observación de cada estado $\\mathbf{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cMFvcHxS3eva",
   "metadata": {
    "id": "cMFvcHxS3eva"
   },
   "source": [
    "**a. Dibuje el diagrama de estados correspondiente al HMM definido por los parámetros descritos a continuación:**\n",
    "\n",
    "`Nota:` Incluir el diagrama en una imagen en la entrega o en el informe de la práctica.\n",
    "\n",
    "* Número de estados, $N=4$.\n",
    "* Probabilidades iniciales de ocupación de cada estado:\n",
    "$$\n",
    "\\pi = [0.4\\; 0.3\\; 0.2\\; 0.1]\n",
    "$$.\n",
    "* Matriz de probabilidades de transición: \n",
    "$$A=\\begin{bmatrix}\n",
    "0.75 & 0.1 & 0.05 & 0.1 \\\\ \n",
    "0.1 & 0.75 & 0.1 & 0.05 \\\\ \n",
    "0.05 & 0.1 & 0.75 & 0.1\\\\ \n",
    "0.1 & 0.05 & 0.1 & 0.75\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* Cada estado tiene una distribución de observación (o distribución de emisión) Gaussiana bivariada. Cada Gaussiana se encuentra caracterizada por los siguientes parámetros:\n",
    "\n",
    "  - $\\mathbf{B}_1$:\n",
    "$$\n",
    "\\mu_1 = [-1,\\;0]\n",
    "\\;;\\; \\Sigma_1 = \\mathcal{I}*4\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_2$:\n",
    "$$\n",
    "\\mu_1 = [5,\\;-1]\n",
    "\\;;\\; \\Sigma_1 = \\mathcal{I}\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_3$:\n",
    "$$\n",
    "\\mu_1 = [4,\\;7.5]\n",
    "\\;;\\; \\Sigma_1 = \\begin{bmatrix}\n",
    "5.0 & -2.0\\\\ \n",
    "-2.0 & 3.0 \n",
    "\\end{bmatrix}\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_4$:\n",
    "$$\n",
    "\\mu_1 = [-7.5,\\;0]\n",
    "\\;;\\; \\Sigma_1 = \\begin{bmatrix}\n",
    "1.0 & 0.0\\\\ \n",
    "0.0 & 4.0 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**`Nota`**: Haga uso de la clase `GaussianHMM` de `hmmlearn` para la implementación de este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7O0_fXB5QtM",
   "metadata": {
    "id": "f7O0_fXB5QtM"
   },
   "source": [
    "**b.) Inicialice el HMM anterior mediante el uso de la clase ``hmmlearn.GaussianHMM``.**\n",
    "\n",
    "El paquete `hmmlearn` [https://hmmlearn.readthedocs.io/en/latest/api.html] es un paquete de software libre desarrollado mediante el uso de scikit-learn, Numpy y matplotlib para el desarrollo e implementacion de los algoritmos destinados al entrenamiento, inferencia y muestreo de diferentes tipos modelos ocultos de Markov (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KAU9j6VL5ah8",
   "metadata": {
    "id": "KAU9j6VL5ah8"
   },
   "outputs": [],
   "source": [
    "# Definición de las variables\n",
    "# Número de estados\n",
    "N = 4\n",
    "\n",
    "# Matriz de Probabilidad de Transicion\n",
    "A = np.array([[0.75, 0.1, 0.05, 0.1],\n",
    "              [0.1, 0.75, 0.1 ,0.05],\n",
    "              [0.05, 0.1, 0.75 ,0.1],\n",
    "              [0.1, 0.05, 0.1 ,0.75]])\n",
    "\n",
    "# Probabilidades iniciales de estado\n",
    "pi = np.array([0.4, 0.3, 0.2, 0.1])\n",
    "\n",
    "# TO DO: Utilización DE HMM.gaussianHMM para la definición del modelo\n",
    "# Fijar la matriz de probabilidades de transición y los estados iniciales.\n",
    "HMM = ...\n",
    "\n",
    "\n",
    "# Vectores de medias\n",
    "mu = np.array([[-1.0, 0.0], [5.0, -1.0], [4, 7.5],[-7.5, 0.0]])\n",
    "\n",
    "# Matrices de covarianza\n",
    "Sigma = []\n",
    "Sigma.append(np.identity(2)*4)\n",
    "Sigma.append(np.identity(2))\n",
    "Sigma.append(np.array([[5.0, -2], [-2, 3.0]]))\n",
    "Sigma.append(np.array([[1.0, 0.0], [0.0, 4.0]]))\n",
    "Sigma = np.array(Sigma)\n",
    "\n",
    "\n",
    "# TO DO: fijar las medias y las matrices de covarianza de las distribuciones de observación\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zSVUy2WC5bKw",
   "metadata": {
    "id": "zSVUy2WC5bKw"
   },
   "source": [
    "**c.) Represente mediante curvas de contorno (función ``contour`` de pyplot) las distribuciones de probabilidad de observación de cada estado. Para la evaluación de la distribución de probabilidad en el plano de variables utilice la clase ``scipy.stats.multivariate_normal``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fK-erEIP5nil",
   "metadata": {
    "id": "fK-erEIP5nil"
   },
   "outputs": [],
   "source": [
    "# Representación de las distribuciones de emisión para cada estado\n",
    "# Definición de los ejes\n",
    "x_axis = np.linspace(-12,12,300)\n",
    "y_axis = np.linspace(-6,14,300)\n",
    "\n",
    "# Generación de matrices con los ejes\n",
    "_X, _Y = np.meshgrid(x_axis, y_axis)\n",
    "# Agrupamiento por pares\n",
    "positions = np.vstack([_X.ravel(), _Y.ravel()]).T\n",
    "\n",
    "colors = ['tab:blue','tab:orange','tab:purple','tab:red']\n",
    "\n",
    "\n",
    "# Generación de la figura\n",
    "fig, ax = plt.subplots(2,2,figsize=(15, 15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for n in range(N):\n",
    "    \n",
    "    # TO DO: Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "    # Utilizar la clase scipy.stats.multivariate_normal\n",
    "    eval_multivariate_normal = ...\n",
    "\n",
    "    prob = np.reshape(eval_multivariate_normal, _X.shape)\n",
    "    # Representación del contorno\n",
    "    ax[n].contour(x_axis, y_axis, prob, colors=colors[n],linewidths=3)\n",
    "        \n",
    "    # Etiquetas y título\n",
    "    ax[n].set_xlabel('Característica 1', fontsize=12)\n",
    "    ax[n].set_ylabel('Característica 2', fontsize=12)\n",
    "    ax[n].set_title('Distribución de emisión \\u03B8_{:.0f}'.format(n+1) )\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L3e_T-uH695M",
   "metadata": {
    "id": "L3e_T-uH695M"
   },
   "source": [
    "### 1.2 Proceso de generación de una secuencia \n",
    "Vamos a hacer uso de un dataset sintético generado exclusivamente para su utilización en esta sesión de prácticas. Para la generación de esta base de datos hemos inicializado en el apartado anterior un modelo oculto de markov haciendo uso del paquete `hmmlearn`. Una vez inicializado el modelo, en este apartado vamos a aplicar el proceso de generación de secuencias para extraer muestras del modelo generativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zq86SzIl7kB3",
   "metadata": {
    "id": "zq86SzIl7kB3"
   },
   "source": [
    "**a.) Utilice la función `gaussianHMM.sample` para generar una secuencia de 4000 muestras del HMM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uChmeDIt6824",
   "metadata": {
    "id": "uChmeDIt6824"
   },
   "outputs": [],
   "source": [
    "# Número de muestras de la secuencia\n",
    "T = 4000\n",
    "# TO DO: utilizar gaussianHMM.sample para generar la base de datos.\n",
    "# X: np.array NxD -> Secuencia de observaciones\n",
    "# Z: np.array Nx1 -> Estados ocultos\n",
    "X, Z = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EtzZTotn7uWc",
   "metadata": {
    "id": "EtzZTotn7uWc"
   },
   "source": [
    "**b.) Represente las primeras `T_repr=50` muestras generadas mediante un scatter plot. Adicionalmente, con el objetivo de visualizar el caracter secuencial de los datos, represente cada una de las muestras unidas con líneas.**\n",
    "\n",
    "**A partir de la representación, la matriz de probabilidades de transición y los estados ocultos generados, analice el comportamiento del modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GilHEPWSONMo",
   "metadata": {
    "id": "GilHEPWSONMo"
   },
   "outputs": [],
   "source": [
    "T_repr=50\n",
    "\n",
    "# Representación de los datos mediante un scatter plot\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Representación de los datos mediante un scatter plot\n",
    "# Para mostrar el desarrollo de la secuencia\n",
    "ax.plot(X[:T_repr,0],X[:T_repr,1],'o-',label='observations',mfc='orange',alpha=0.7)\n",
    "ax.plot(X[0:1,0],X[0:1,1],'or')\n",
    "plt.xlim((np.min(X[:,0]),np.max(X[:,0])))\n",
    "plt.ylim((np.min(X[:,1]),np.max(X[:,1])))\n",
    "ax.set_xlabel('Característica 1', fontsize=12)\n",
    "ax.set_ylabel('Característica 2', fontsize=12)\n",
    "ax.set_title('Base de datos sintética - Representación Secuencial' )\n",
    "\n",
    "for n in range(N):\n",
    "    #  TO DO: Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "    # y representación de los contornos\n",
    "    eval_multivariate_normal = ...\n",
    "    prob = np.reshape(eval_multivariate_gaussian, _X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kI_CMM9R8qF5",
   "metadata": {
    "id": "kI_CMM9R8qF5"
   },
   "source": [
    "### 1.3 Comparativa con otros modelos ocutos de Markov.\n",
    "\n",
    "En este apartado se propone la definición de dos modelos alternativos al generado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-summary",
   "metadata": {
    "id": "floating-summary"
   },
   "source": [
    "**a.) Repita los apartados del ejercicio 1.1 y 1.2 con el modelo `HMM2` definido por los parámetros que se representan a continuación:**\n",
    "\n",
    "NOTA: Incluir una imagen representando el diagrama de estados en el informe de la práctica. \n",
    "\n",
    "* Número de estados, $N=4$.\n",
    "* Probabilidades iniciales de estado:\n",
    "\n",
    "$$\n",
    "\\pi = [0.4\\; 0.3\\; 0.2\\; 0.1]\n",
    "$$.\n",
    "\n",
    "* Matriz de probabilidades de transición: \n",
    "$$A=\\begin{bmatrix}\n",
    "0.75 & 0.1 & 0.05 & 0.1 \\\\ \n",
    "0.1 & 0.75 & 0.1 & 0.05 \\\\ \n",
    "0.05 & 0.1 & 0.75 & 0.1\\\\ \n",
    "0.1 & 0.05 & 0.1 & 0.75\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* Cada estado dispone de un Modelo de Mezclas de Gaussianas (GMM) bivariado como distribuciones de probabilidad de observación. Cada GMM se encuentra caracterizado por: \n",
    "\n",
    "  - $\\mathbf{B}_1$:\n",
    "$$\n",
    "\\pi_1 = [0.3\\; 0.3\\; 0.4]\\;;\\; \\mu_1 = \\begin{bmatrix}\n",
    "-2.0 & 2.0\\\\ \n",
    "0.0 & -1.0\\\\ \n",
    "-3.0 & 1.0 \n",
    "\\end{bmatrix}\\;;\\; \\Sigma_1 = \\mathcal{I}\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_2$:\n",
    "$$\n",
    "\\pi_2 = [0.2\\; 0.5\\; 0.3]\\;;\\; \\mu_2 = \\begin{bmatrix}\n",
    "5.0 & -1.0\\\\ \n",
    "5.0 &  1.0\\\\ \n",
    "6.0 & -1.0\n",
    "\\end{bmatrix}\\;;\\; \\Sigma_2 = \\mathcal{I}\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_3$:\n",
    "$$\n",
    "\\pi_3 = [0.4\\; 0.3\\; 0.3]\\;;\\; \\mu_3 = \\begin{bmatrix}\n",
    "3.0 & -5.0\\\\ \n",
    "1.0 &  10.0\\\\ \n",
    "5.0 & 8.0\n",
    "\\end{bmatrix}\\;;\\; \\Sigma_3 = \\mathcal{I}\n",
    "$$.\n",
    "\n",
    "  - $\\mathbf{B}_4$:\n",
    "$$\n",
    "\\pi_1 = [0.5\\; 0.3\\; 0.2]\\;;\\; \\mu_1 = \\begin{bmatrix}\n",
    "-8.0 & -0.0\\\\ \n",
    "-8.0 &  2.0\\\\ \n",
    "-8.0 &  -2.0\n",
    "\\end{bmatrix}\\;;\\; \\Sigma_1 = \\mathcal{I}\n",
    "$$.\n",
    "\n",
    "**¿Qué tipo de HMM es según su topología?¿En qué difieren los modelos `HMM1` y `HMM2`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6WaNkAip-r2N",
   "metadata": {
    "id": "6WaNkAip-r2N"
   },
   "outputs": [],
   "source": [
    "# Distribuciones de Probabilidad de emisión: GMM para cada estado\n",
    "# Numero de componentes gaussianas\n",
    "n_gaussians = 3\n",
    "\n",
    "# 1) Pesos de las componentes gaussianas de las GMM\n",
    "# pesos_{i,j} corresponde al peso de la componente j del estado i ''\n",
    "weights2 = np.array([[0.3, 0.3, 0.4],\n",
    "                  [0.2, 0.5, 0.3],\n",
    "                  [0.4, 0.3, 0.3],\n",
    "                  [0.5, 0.3, 0.2]])\n",
    "\n",
    "# 2) Vectores de medias de las componentes gaussianas de las GMM\n",
    "# mu_{i,j} corresponde al vector de medias de la componente j del estado i (vector 2D)\n",
    "mu2 = np.array([[[-2.0, 2.0], [0.0, -1], [-3.0, 1.0]],\n",
    "               [[5.0, 0.0], [5.0, -1.0], [6.0, -1.0]],\n",
    "               [[3.0, 5.0], [1.0, 10], [5.0, 8.0]],\n",
    "               [[-8.0, 0.0], [-8.0, 2], [-8.0, -2.0]]])\n",
    "\n",
    "\n",
    "#3) Matrices de covarianza de las componentes Gaussianas de las GMM\n",
    "# sigma_{i,j} corresponde a la matriz de covarianzas de la componente j del estado i (vector 2D)\n",
    "sigma2 = np.tile(np.identity(2), (4, 3, 1, 1))\n",
    "\n",
    "# Inicialización del modelo:\n",
    "# TO DO: Generación de la variable HMM2 de clase GMMHMM\n",
    "HMM2 = ...\n",
    "...\n",
    "\n",
    "######################################################################### 1.1C\n",
    "# Representación de las distribuciones de emisión para cada estado\n",
    "# Definición de los ejes\n",
    "x_axis = np.linspace(-12,12,300)\n",
    "y_axis = np.linspace(-6,14,300)\n",
    "\n",
    "# Generación de matrices con los ejes\n",
    "_X, _Y = np.meshgrid(x_axis, y_axis)\n",
    "# Agrupamiento por pares\n",
    "positions = np.vstack([_X.ravel(), _Y.ravel()]).T\n",
    "\n",
    "colors = ['tab:blue','tab:orange','tab:purple','tab:red']\n",
    "\n",
    "# Generación de la figura\n",
    "fig, ax = plt.subplots(2,2,figsize=(15, 15))\n",
    "\n",
    "ax = ax.ravel()\n",
    "for n in range(N):\n",
    "    \n",
    "    for g in range(n_gaussians):\n",
    "        # TO DO: Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "        eval_multivariate_gaussian= ...\n",
    "        prob = np.reshape(eval_multivariate_gaussian), _X.shape)\n",
    "        # Representación del contorno\n",
    "        ax[n].contour(x_axis, y_axis, prob, colors=colors[g],linewidths=3)\n",
    "        # Etiquetas y título\n",
    "        ax[n].set_xlabel('Característica 1', fontsize=12)\n",
    "        ax[n].set_ylabel('Característica 2', fontsize=12)\n",
    "        ax[n].set_title('Distribución de emisión \\u03B8_{:.0f}'.format(n+1) )\n",
    "\n",
    "plt.show();\n",
    "\n",
    "######################################################################### 1.2\n",
    "X2, Z2 = HMM2.sample(T)\n",
    "\n",
    "T_repr=50\n",
    "\n",
    "# Representación de los datos mediante un scatter plot\n",
    "fig2,ax2 = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Representación de los datos mediante un scatter plot\n",
    "# Para mostrar el desarrollo de la secuencia\n",
    "ax2.plot(X2[:T_repr,0],X2[:T_repr,1],'o-',label='observations',mfc='orange',alpha=0.7)\n",
    "ax2.plot(X2[0:1,0],X2[0:1,1],'or')\n",
    "plt.xlim((np.min(X2[:,0]),np.max(X2[:,0])))\n",
    "plt.ylim((np.min(X2[:,1]),np.max(X2[:,1])))\n",
    "ax2.set_xlabel('Característica 1', fontsize=12)\n",
    "ax2.set_ylabel('Característica 2', fontsize=12)\n",
    "ax2.set_title('Base de datos sintética - Representación Secuencial' )\n",
    "\n",
    "\n",
    "for n in range(N):\n",
    "  for g in range(n_gaussians):\n",
    "    # TO DO: Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "    eval_multivariate_gaussian= ...\n",
    "    prob = np.reshape(eval_multivariate_gaussian, _X.shape)\n",
    "    ax2.contour(x_axis, y_axis, prob,colors=colors[n],linewidths=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-usage",
   "metadata": {
    "id": "religious-usage"
   },
   "source": [
    "**b) Repetir los apartados del ejercicio 1.1 y 1.2 utilizando un modelo `HMM3` que se diferencia del modelo `HMM1` en la matriz de probabilidades de transición y las probabilidades iniciales de estado:**\n",
    "\n",
    "$$A=\\begin{bmatrix}\n",
    "0.7 & 0.15 & 0.15 & 0 \\\\ \n",
    "0 & 0.8 & 0.15 & 0.05 \\\\ \n",
    "0 & 0 & 0.9 & 0.1\\\\ \n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi = [0.9\\; 0.1\\; 0.0\\; 0.0]\n",
    "$$\n",
    "\n",
    "**`Nota`**: Las secuencias X y Z generadas tras el muestreo de `HMM3` se guardarán en las variables X3 y Z3, para no sobreescribir las secuencias ya generadas.\n",
    "\n",
    "\n",
    "**¿Qué tipo de HMM es según su topología?¿En qué difieren los modelos `HMM1` y `HMM2`?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-desire",
   "metadata": {
    "id": "equipped-desire"
   },
   "outputs": [],
   "source": [
    "# Guardamos el modelo anterior con el nombre HMM1\n",
    "import copy\n",
    "\n",
    "\n",
    "# TO DO: Definición Matriz de Probabilidad de Transicion\n",
    "A3 = ... \n",
    "# TO DO: Definición\n",
    "pi3 = ...\n",
    "\n",
    "# TO DO: Definición del modelo HMM3\n",
    "HMM3 = ...\n",
    "\n",
    "# Apartado c)\n",
    "\n",
    "# Generación de la figura\n",
    "fig, ax = plt.subplots(2,2,figsize=(15, 15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for n in range(N):\n",
    "    \n",
    "    # TO DO: Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "    eval_multivariate_gaussian =...\n",
    "    prob = np.reshape(eval_multivariate_gaussian, _X.shape)\n",
    "    # Representación del contorno\n",
    "    ax[n].contour(x_axis, y_axis, prob, colors=colors[n],linewidths=3)\n",
    "        \n",
    "    # Etiquetas y título\n",
    "    ax[n].set_xlabel('Característica 1', fontsize=12)\n",
    "    ax[n].set_ylabel('Característica 2', fontsize=12)\n",
    "    ax[n].set_title('Distribución de emisión \\u03B8_{:.0f}'.format(n+1) )\n",
    "\n",
    "# Apartado d)\n",
    "# Muestreo ancestral -> Atributo .sample\n",
    "# X: np.array NxD -> Secuencia de observaciones\n",
    "# Z: np.array Nx1 -> Estados ocultos\n",
    "X3, Z3 = HMM3.sample(T)\n",
    "\n",
    "\n",
    "# Apartado e)\n",
    "# Representación de los datos mediante un scatter plot\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Representación de los datos mediante un scatter plot\n",
    "# Para mostrar el desarrollo de la secuencia\n",
    "ax.plot(X3[:T_repr,0],X3[:T_repr,1],'.-',label='observations',mfc='orange',alpha=0.7)\n",
    "ax.plot(X3[0:1,0],X3[0:1,1],'o-r')\n",
    "plt.xlim((np.min(X3[:,0]),np.max(X3[:,0])))\n",
    "plt.ylim((np.min(X3[:,1]),np.max(X3[:,1])))\n",
    "ax.set_xlabel('Característica 1', fontsize=12)\n",
    "ax.set_ylabel('Característica 2', fontsize=12)\n",
    "ax.set_title('Base de datos sintética - Representación Secuencial' )\n",
    "\n",
    "for n in range(N):\n",
    "    # Evaluación de cada una de las componentes gaussianas en los ejes\n",
    "    eval_multivariate_gaussian=...\n",
    "    prob = np.reshape(eval_multivariate_gaussian, _X.shape)\n",
    "    # Representación del contorno\n",
    "    ax.contour(x_axis, y_axis, prob, colors=colors[n],linewidths=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9f7f8",
   "metadata": {
    "id": "6ee9f7f8"
   },
   "source": [
    "## Parte 2: Problemas clásicos de los modelos ocultos de Markov."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-gentleman",
   "metadata": {
    "id": "expanded-gentleman"
   },
   "source": [
    "### 2.1: Problema de puntuación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-restriction",
   "metadata": {
    "id": "clear-restriction"
   },
   "source": [
    "Dado el modelo $\\lambda = (A,  \\mathbf{B}, \\pi)$ y un conjunto de observaciones $\\mathrm{X}= \\{ \\mathrm{x}_1, ..., \\mathrm{x}_N \\}$ el cálculo de $P(X|\\lambda)$ o la verosimilitud del modelo $\\lambda$ con los datos $\\mathrm{X}$ se realiza mediante el algoritmo *Forward*.\n",
    "\n",
    "Este algoritmo queda descrito por el siguiente pseudocodigo:\n",
    "\n",
    "___________________________________________\n",
    "**Algoritmo Forward**\n",
    "Entrada: $ \\boldsymbol{X}, A, \\mathbf{B}, \\pi$\n",
    "___________________________________________\n",
    "- $[\\phi_1] = \\text{Eval_Px_z}(X_1, \\mathbf{B})$\n",
    "- $[\\alpha_1, C_1] = \\text{Normalize}(\\phi_1\\odot\\pi)$\n",
    "\n",
    "- **for** $t=2:N$ **do**:\n",
    "  - $[\\phi_t] = \\text{Eval_Px_z}(X_t, \\mathbf{B})$\n",
    "  - $[\\alpha_t, C_t] = \\text{Normalize}(\\phi_t \\odot (A^T\\alpha_{t-1}))$\n",
    "\n",
    "- **Return** $\\alpha_{1:N}$, $\\log P(X_{1:N}) = \\sum_t \\log C_t$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4pxyRH-LqFY",
   "metadata": {
    "id": "d4pxyRH-LqFY"
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Función Normalize\n",
    "# Descripción: Función para la normalización de un vector. Se va a utilizar para el calculo\n",
    "# de las probabilidades a posteriori del estado P(Z|X) = P(X,Z)/P(X) \n",
    "#\n",
    "# Entradas:\n",
    "#   u: np.array Kx1 correspondiente a P(X|Z)\n",
    "# Salidas:\n",
    "#   C: 1x1 P(X) probabilidad marginal de la secuencia de observaciones (marginalizando los estados)\n",
    "#   alfa: Kx1 P(Z|X) probabilidades a posteriori de cada estado\n",
    "####################################################################################\n",
    "def Normalize(u):\n",
    "    C = np.sum(u)\n",
    "    alfa = u/C\n",
    "    \n",
    "    return C,alfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-cathedral",
   "metadata": {
    "id": "integrated-cathedral"
   },
   "source": [
    "**a.) Complete la función Eval_Px_z para calcular la probabilidad de observación dado cada un estado para el modelo `HMM1` en el que la probabilidad de observación de cada estado viene definida por una distribución Gaussiana bivariada.**\n",
    "\n",
    "**Compruebe su funcionamiento con la primera muestra de nuestra base de datos X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-automation",
   "metadata": {
    "id": "complimentary-automation"
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Función eval_Px_Z\n",
    "# Descripción: Función para la obtención de P(X|Z). Evaluación de X en cada uno de \n",
    "# las gaussianas (estados)\n",
    "#\n",
    "# Entradas:\n",
    "#   data: np.array NxK secuencia de observaciones de entrada\n",
    "#   B: Lista con las Gaussianas de cada estado. Lista de elementos clase multivariate_normal\n",
    "# Salidas:\n",
    "#    result: P(X|Z) : Probabilidad devuelta por el Gaussiana de cada estado\n",
    "####################################################################################\n",
    "def eval_Px_Z(data,B):\n",
    "\n",
    "    fi = np.empty((len(B),1))\n",
    "    for k,g in enumerate(B):\n",
    "        # TO DO: Evaluación del la probabilidad de observación Gaussiana para la muestra\n",
    "        fi[k] = ...\n",
    "        # Se agrupan en una lista todas las probabilidades devueltas por cada estado\n",
    "        # Se calcula la exponencial para obtener un valor de probabilidad.\n",
    "    return fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cGpxnpIWsG3",
   "metadata": {
    "id": "7cGpxnpIWsG3"
   },
   "outputs": [],
   "source": [
    "# Se almacenan las Gaussianas de cada estado en una lista.\n",
    "# Al no ser entrenadas, necesitan la definición de todos sus parámetros.\n",
    "B = []\n",
    "for n in range(N):\n",
    "    Gaussian_states = multivariate_normal(mean=mu[n], cov=Sigma[n])\n",
    "    B.append(Gaussian_states)\n",
    "\n",
    "# TO DO: LLamada a la función eval_Px_Z\n",
    "fi= ...\n",
    "\n",
    "# TO DO: Devolver X[0], P(X[0]|lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NkBzRwbRMGsW",
   "metadata": {
    "id": "NkBzRwbRMGsW"
   },
   "source": [
    "**b.) A partir del pseudocódigo del enunciado, complete la función Forward que realiza el proceso completo para el cálculo de la verosimilitud de una secuencia $\\boldsymbol{X}$ dado el HMM del primer ejercicio.** \n",
    "\n",
    "**Analice la función Forward ¿Qué representan los parámetros $\\phi$, $\\alpha$ y $C$?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D4lfZbGyXARb",
   "metadata": {
    "id": "D4lfZbGyXARb"
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Función Forward\n",
    "# Descripción: Implementa el algoritmo forward para la obtención de P(X|HMM)\n",
    "#\n",
    "# Entradas:\n",
    "#   data: np.array NxK secuencia de observaciones de entrada\n",
    "#   A:    np.array KxK Matriz de probabilidades de transición\n",
    "#   pi:   np.list Kx1 Probabilidades de estado iniciales\n",
    "#   B: Lista con los parámetros de los GMMs de cada estado\n",
    "# Salidas:\n",
    "#    log_likelihood: Logaritmo de la verosimilitud P(X\\HMM)\n",
    "####################################################################################\n",
    "def Forward(data,A,pi,B):\n",
    "    # Inicialización de las variables: logaritmo de la verosimilitd\n",
    "    # alpha: Matriz en la que se van a almacenar las P(Z|X)\n",
    "    log_likelihood = 0\n",
    "    alpha= np.zeros((len(B),np.size(data,0)))\n",
    "    \n",
    "    # 1) Primera muestra\n",
    "    pi = pi.reshape((len(B),1))\n",
    "    # TODO Calcular fi P(X_i|Z) sin normalizar\n",
    "    fi = ...\n",
    "\n",
    "    # TODO calcular alfa P(X_i|Z) y C P(X_i)\n",
    "    C,alfa =  ...\n",
    "\n",
    "    # Almacenamiento de las prob\n",
    "    alpha[:,0]=alfa.ravel()\n",
    "    \n",
    "    # TO DO: Calculo del logaritmo de la probabilidad para la primera muestra\n",
    "    log_likelihood = ... \n",
    "    \n",
    "    # 2) Para el resto de las muestras \n",
    "    for i in range(1,np.size(data,0)):\n",
    "\n",
    "        # 2.1 TO DO:  Calculo de fi \n",
    "        fi = ...\n",
    "        # 2.2 TO DO:calculo de alfa en el instante t dado alfa en t-1\n",
    "        C,alfa = ...\n",
    "\n",
    "        alpha[:,i]=alfa.ravel()\n",
    "        # 2.3 TO DO: Se suma el logaritmo de la probabilidad marginal\n",
    "        log_likelihood= ...\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-experience",
   "metadata": {
    "id": "seeing-experience"
   },
   "outputs": [],
   "source": [
    "# LLamada a la función Forward -> Devuelve el logaritmo de la verosimilitud \n",
    "loglikelihood= Forward(data=X,A=A,pi=pi,B=B)\n",
    "print('El logaritmo de la verosimilitud del modelo con la secuencia de observaciones X P(X|\\u03BB) es {:.4f}'.format(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-energy",
   "metadata": {
    "id": "funded-energy"
   },
   "source": [
    "**b.) Compruebe el resultado obtenido en el apartado anterior con el resultado al aplicar la función de `hmmlearn` (método `.score`) para el cálculo de la verosimilitud mediante el algoritmo *Forward*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-simulation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "religious-simulation",
    "outputId": "990ed5bd-faca-4894-8d7c-7210bd0ed804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El logaritmo de la verosimilitud del modelo con la secuencia de observaciones X P(X|λ) es -17941.9567\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implementación del algoritmo Forward en el atributo .score del HMM\n",
    "loglikelihood = ... \n",
    "\n",
    "print('El logaritmo de la verosimilitud del modelo con la secuencia de observaciones X P(X|\\u03BB) es {:.4f}'.format(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n_-6G0-UdNjE",
   "metadata": {
    "id": "n_-6G0-UdNjE"
   },
   "source": [
    "**c.) ¿Cuál de los tres modelos `HMM`, `HMM2` y `HMM3` maximiza el logaritmo de la verosimilitud? ¿Es este resultado el esperado? Justifique su respuesta.**\n",
    "\n",
    "**`Nota`**: Utilice para ello la función `Forward` implementada anteriormente o la función disponible en `hmmlearn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TQHWCbj1eKwp",
   "metadata": {
    "id": "TQHWCbj1eKwp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "chief-visitor",
   "metadata": {
    "id": "chief-visitor"
   },
   "source": [
    "### 2.1: Problema de reconocimiento de estados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-theorem",
   "metadata": {
    "id": "vanilla-theorem"
   },
   "source": [
    "Dado una secuencia de observaciones $X = \\{\\mathrm{x}_1,...,\\mathrm{x}_N\\}$ y un modelo $\\lambda = (\\pi, A, \\mathbf{B})$ el algoritmo de *viterbi* permite encontrar la secuencia de estados ocultos más probable , es decir, permite obtener la secuencia de estados que mejor ''explica'' las observaciones.\n",
    "\n",
    "El algoritmo de viterbi queda descrito por el siguiente pseudocódigo:\n",
    "\n",
    "_________________________________________________________\n",
    "**Algoritmo de Viterbi** Entrada: $\\boldsymbol{X}$, $A$, $\\pi$, $\\mathbf{B}$\n",
    "_________________________________________________________\n",
    "- $a_1=\\boldsymbol{0}$\n",
    "- $\\phi_1 = \\text{eval_Px_Z}(X_1,\\mathbf{B})$\n",
    "- $\\delta = \\pi \\odot \\phi_1$\n",
    "- **for** $t=2:T$ **do**:\n",
    "  - **for** $j = 1:N$ **do**:\n",
    "  - $\\phi_t = \\text{eval_Px_Z}(X_t,\\mathbf{B})$\n",
    "  - $[a_t(j), \\delta_t(j)] =\\text{max}_i(\\text{log}\\delta_{t-1}(:) + \\text{log}A_{ij} +\\text{log}\\phi_t(j))$ \n",
    "\n",
    "- $S_T = \\text{arg}\\text{max}(\\delta_T)$\n",
    "- **for** $t = N-1:1$ **do**\n",
    "  - $S_t = a_{t-1}S_{t+1}$\n",
    "\n",
    "- **Return** S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-jacket",
   "metadata": {
    "id": "waiting-jacket"
   },
   "source": [
    "**a.) Complete la función `viterbi` para que integre el algoritmo de viterbi para la decodificación de la secuencia más probable de estados dada una secuencia de observaciones.**\n",
    "\n",
    "**Describa brevemente el significado de cada una de las variables del algoritmo y compruebe la secuencia resultante con los estados obtenidos al generar la base de datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-sleeping",
   "metadata": {
    "id": "broad-sleeping"
   },
   "outputs": [],
   "source": [
    "# %% Implementación del algoritmo de Viterbi:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "####################################################################################\n",
    "# Función Viterbi\n",
    "# Descripción: Implementa el algoritmo de viterbi para la generación de la secuencia\n",
    "# de estados más probable dado un conjunto de observaciones y un modelo\n",
    "#\n",
    "# Entradas:\n",
    "#   data: np.array NxK secuencia de observaciones de entrada\n",
    "#   A:    np.array KxK Matriz de probabilidades de transición\n",
    "#   pi:   np.list Kx1 Probabilidades de estado iniciales\n",
    "#   B: Lista con los parámetros de los GMMs de cada estado\n",
    "# Salidas:\n",
    "#    S:  np.array Nx1 con la secuencia de estados más probable\n",
    "####################################################################################\n",
    "def viterbi(data,A,B,pi):\n",
    "    # Inicialización de Matriz en la que vamos a ir guardando los estados más probables\n",
    "    a = np.zeros((np.size(A,0),np.size(data,0)-1))\n",
    "    # Inicialización en la que se van a ir guardando las mejores puntuaciones\n",
    "    omega = np.zeros((np.size(A,0),np.size(data,0)))\n",
    "    \n",
    "    # 1) Incializacion Primera muestra\n",
    "    pi = pi.reshape((len(B),1))\n",
    "    fi = eval_Px_Z(data[0,:],B)\n",
    "    omega[:,0] = np.log((pi*fi).ravel())\n",
    "    \n",
    "    # 2) Recursión\n",
    "    for t in range(1,np.size(data,0)):\n",
    "        for k in range(len(B)):\n",
    "\n",
    "            # TO DO: Calculo de P(X|Z)\n",
    "            fi= \n",
    "\n",
    "            # TO DO: calculo del logaritmo de las puntuaciones\n",
    "            prob = ...\n",
    "\n",
    "            # TO DO: Calculo de la probabilidad máxima\n",
    "            omega[k,t] = ...\n",
    "            # TO DO: Calculo del estado anterior más probable\n",
    "            a[k,t-1] = ...\n",
    "    \n",
    "    # Array con la secuencia de estados final\n",
    "    S=np.zeros(np.size(data,0))\n",
    "    \n",
    "    # 3) Terminación \n",
    "    ultimo_estado = np.argmax(omega[:,-1:])\n",
    "    S[0] = ultimo_estado\n",
    "        \n",
    "    # 4) Path Backtracking\n",
    "    indice_back = 1\n",
    "    for i in range(np.size(data,0)-2,-1,-1):\n",
    "        S[indice_back] = a[int(ultimo_estado),i]\n",
    "        ultimo_estado = S[indice_back]\n",
    "        indice_back +=1\n",
    "    \n",
    "    S = np.flip(S,axis=0)\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-victim",
   "metadata": {
    "id": "coordinate-victim"
   },
   "outputs": [],
   "source": [
    "# TO DO: LLamada a viterbi \n",
    "SeqViterbi = ...\n",
    "print(\"La secuencia de estados ocultos más probable es \",SeqViterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-guidance",
   "metadata": {
    "id": "preceding-guidance"
   },
   "source": [
    "**b.) Haga uso de la función `.decode` de ``hmmlearn`` para la implementación del algoritmo viterbi para la decodificación de la secuencia más probable de estados dada una secuencia de observaciones. ¿Coincide la secuencia con la devuelta por la función previamente implementada?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-table",
   "metadata": {
    "id": "significant-table"
   },
   "outputs": [],
   "source": [
    "# TO DO: Implementacion de viterbi mediante .decode(algorithm='viterbi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-scanner",
   "metadata": {
    "id": "absent-scanner"
   },
   "source": [
    "### 2.3: Problema de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-foster",
   "metadata": {
    "id": "asian-foster"
   },
   "source": [
    "Dado un conjunto de observaciones $X=\\{\\mathrm{x}_1,...,\\mathrm{x}_N\\}$ el cálculo de los parámetros que definen el modelo oculto de markov $\\lambda = \\left( \\pi, A, \\mathbf{B}\\right)$ que maximizan la verosimilitud de los datos dado el modelo $P(X|\\lambda)$ se obtiene mediante el algoritmo EM o, en este caso, el algoritmo *Baum-Welch*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-scenario",
   "metadata": {
    "id": "certain-scenario"
   },
   "source": [
    "**a) Utilice la función `.fit` para entrenar un modelo oculto de markov a partir de los datos sintéticos generados en el ejercicio 1.**\n",
    "\n",
    "**Analice los parámetros obtenidos y compárelos con el modelo generador de los datos. ¿Qué ocurre con el parámetro de los estados iniciales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-thailand",
   "metadata": {
    "id": "representative-thailand"
   },
   "outputs": [],
   "source": [
    "# TO DO: Utilización de .fit para el entrenamiento de la clase Gaussian HMM\n",
    "model_trained = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-scientist",
   "metadata": {
    "id": "hungry-scientist"
   },
   "source": [
    "**b.) Realice el entrenamiento del modelo utilizando varias secuencias generadas sintéticamente a partir del muestreo ancestral del primer modelo. Compare los parámetros del modelo aprendido con el primer modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-cross",
   "metadata": {
    "id": "regulated-cross"
   },
   "outputs": [],
   "source": [
    "# Supongamos que tenemos diferentes secuencias de entrenamiento\n",
    "X1,Z1 = HMM.sample(4000)\n",
    "X2,Z2 = HMM.sample(4000)\n",
    "X3,Z3 = HMM.sample(4000)\n",
    "X4,Z4 = HMM.sample(4000)\n",
    "X5,Z5 = HMM.sample(4000)\n",
    "\n",
    "# Concatenamos todas las secuencias que tenemos\n",
    "X_total = np.concatenate([X,X1,X2,X3,X4,X5],axis=0)\n",
    "# Determinamos la longitud de cada cadena\n",
    "lengths = np.array([len(X),len(X1), len(X2), len(X3),len(X4), len(X5)])\n",
    "\n",
    "# TO DO: Utilización de .fit para el entrenamiento de la clase Gaussian HMM\n",
    "model_trained = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-racing",
   "metadata": {
    "id": "partial-racing"
   },
   "source": [
    "## Parte 3: Clasificación de patrones temporales mediante HMMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-blame",
   "metadata": {
    "id": "smoking-blame"
   },
   "source": [
    "**Caso Ficticio**: Una empresa dedicada al suministro y gestión de maquinaria industrial desea identificar si las averías presentes en sus equipos se deben a un fallo en un componente o debido a un uso indebido de los mismos. Esto es considerado una tarea clave para la empresa, pues en el caso de que las averías se debiesen a un fallo debido a su incorrecto uso, serían los usuarios los responsables de financiar el arreglo.\n",
    "\n",
    "Para ello, el personal técnico decide instalar determinados sensores para medir la vibración y la velocidad de funcionamiento de las máquinas. Tras varios meses de funcionamiento, los sensores capturan secuencias de ambas medidas normalizadas en diferentes circunstancias.\n",
    "\n",
    "De esta forma, se recogen 10 secuencias asociadas a averías debido al fallo de un componente, 10 secuencias asociadas a averías debido a su uso indebido y, por último, 10 secuencias en las que el equipo no presenta avería alguna.\n",
    "\n",
    "Las medidas se pueden encontrar en los ficheros \"uso_inapropiado.csv\", \"fallo_componente.csv\" y \"sin_averias.csv\".\n",
    "\n",
    "De cara a poder clasificar dichas averías, se decide entrenar un modelo oculto de Markov para modelar cada una de los casos de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-metallic",
   "metadata": {
    "id": "interstate-metallic"
   },
   "source": [
    "**a.) Cargue los datos de entrenamiento haciendo uso de la función `pandas.read_csv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-transparency",
   "metadata": {
    "id": "overall-transparency"
   },
   "outputs": [],
   "source": [
    "# Carga de los datos\n",
    "import pandas as pd\n",
    "\n",
    "uploaded = files.upload()\n",
    "uploaded = files.upload()\n",
    "uploaded = files.upload()\n",
    "\n",
    "\n",
    "sin_averias = pd.read_csv('sin_averias.csv',index_col=0).values\n",
    "fallo_componente = pd.read_csv('fallo_componente.csv',index_col=0).values\n",
    "uso_inapropiado = pd.read_csv('uso_inapropiado.csv',index_col=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-aging",
   "metadata": {
    "id": "static-aging"
   },
   "source": [
    "**b.) Realice el entrenamiento de un modelo oculto de markov con distribuciones de emisión gaussianas que modele cada uno de los casos de estudio. Para ello, al igual que se hizo en el ejercicio anterior, utilice el paquete ``hmmlearn``.**\n",
    "\n",
    "**Represente los parámetros de cada uno de los modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-comparison",
   "metadata": {
    "id": "biological-comparison"
   },
   "outputs": [],
   "source": [
    "# Entrenamiento de un modelo por cada clase\n",
    "lengths = np.array([50 for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-produce",
   "metadata": {
    "id": "broad-produce"
   },
   "source": [
    "**c.) Tras el entrenamiento de los modelos, se obtiene una secuencia relacionada con la posible avería de un equipo nuevo. Cargue los datos del fichero ``test.csv``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hIL-BT7_2fjz",
   "metadata": {
    "id": "hIL-BT7_2fjz"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19KhpHTG2f8N",
   "metadata": {
    "id": "19KhpHTG2f8N"
   },
   "source": [
    "\n",
    "**A partir de los modelos generados anteriormente ¿Está la máquina averiada?**\n",
    "\n",
    "**En caso de estar averiada ¿Dicha avería es debido a un fallo de fabricación o a un uso indebido?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-spirituality",
   "metadata": {
    "id": "veterinary-spirituality",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sequence = pd.read_csv('test.csv',index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-mouse",
   "metadata": {
    "id": "fourth-mouse"
   },
   "outputs": [],
   "source": [
    "log_likelihood_usoInapropiado = ...\n",
    "log_likelihood_falloComponente = ...\n",
    "log_likelihood_sinAverias = ..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PR2_PIT_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
